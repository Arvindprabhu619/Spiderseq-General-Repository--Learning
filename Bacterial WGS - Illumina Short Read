Get docker installed in ubuntu, refer docker readme

Then

Step 3 â€” Create & build the unified WGS Docker image (detailed)
Goal: produce a reproducible Docker image wgs_bacteria:1.0 that contains all tools for the WGS pipeline (download, QC, trim, assembly, typing, AMR, phylogeny).

Work from your project root â€” the same $PROJECT you created earlier (e.g. ~/wgs_bacteria_project).

3.1 â€” Create the files

Open a terminal and run these commands (they create files with the exact contents we discussed):

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/Desktop$ cd ~/wgs_bacteria_project
pwd
ls
/home/spiseq/wgs_bacteria_project
spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ 

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ # create Dockerfile
cat > Dockerfile <<'EOF'
# Dockerfile â€” unified bacterial WGS image
FROM continuumio/miniconda3:latest

ENV DEBIAN_FRONTEND=noninteractive
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      build-essential ca-certificates curl wget git unzip bzip2 \
      libbz2-dev liblzma-dev libzstd1 pigz procps && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

COPY environment.yml /tmp/environment.yml

RUN conda install -y -n base -c conda-forge mamba && \
    mamba env create -n wgs -f /tmp/environment.yml && \
    conda clean -afy && \
    rm -f /tmp/environment.yml

SHELL ["conda", "run", "-n", "wgs", "/bin/bash", "-lc"]
ENV PATH=/opt/conda/envs/wgs/bin:$PATH
WORKDIR /work
ENTRYPOINT [ "/bin/bash" ]
EOF

Step 3.2 â€” Build the Docker image

Run this command from inside ~/wgs_bacteria_project:

docker build -t wgs_bacteria:1.0 .

What this does:

Starts from continuumio/miniconda3:latest.

Installs system packages (apt-get).

Copies environment.yml into the image.

Installs mamba and uses it to create the wgs Conda environment.

Cleans temporary files to reduce image size.

Sets the working directory to /work and exposes the wgs environment binaries on PATH.

What we are doing step by step

Create a list of all required packages and versions

Thatâ€™s what the environment.yml file is.

It lists every bioinformatics tool you need for bacterial WGS (FastQC, fastp, SPAdes, Prokka, etc.) with specific versions.

Pinning versions ensures reproducibility: if you rebuild later, the same versions are installed.

Create a Dockerfile

The Dockerfile is a â€œrecipeâ€ for a container.

It starts from a clean base image (Miniconda) and tells Docker how to build the container.

Steps include installing system packages, copying environment.yml, installing mamba, and creating a conda environment inside the image.

Build the Docker image

When you run docker build -t wgs_bacteria:1.0 ., Docker executes the Dockerfile instructions step by step:

Install OS dependencies

Copy environment.yml

Install mamba and create the wgs environment with all tools inside the image

Clean up to reduce image size

At the end, you get a self-contained Docker image that has all WGS tools installed and ready to use.

Use the Docker image

You can now run the container with docker run and all tools will be available inside it.

Your host OS is unaffected â€” nothing is installed globally.

You can mount your project folder so data and results are accessible outside the container.

1ï¸âƒ£ Docker image storage

When you run:

docker build -t wgs_bacteria:1.0 .


Docker creates an image, which is like a snapshot of a Linux system with all your tools installed.

This image lives inside Dockerâ€™s storage on your host, not in your project folder.

Location depends on your OS:

OS	Default Docker storage path
Linux	/var/lib/docker
macOS	inside Docker Desktop VM
Windows	inside Docker Desktop VM

You cannot directly see the files in ~/wgs_bacteria_project; Docker manages them internally.

The image contains all system packages, conda, and tools â€” fully isolated.

Key points:

Dockerfile: Already created, contains all steps to install system packages, copy environment.yml, install mamba, create wgs environment, and set /work as working directory.

Environment: mamba will read your environment.yml and install all WGS tools.

Output: At the end, you will have an image called wgs_bacteria:1.0.

If you face any error in installation of package for docker

1ï¸âƒ£ Save the environment.yml

Inside your project folder (~/wgs_bacteria_project):

nano environment.yml

Then make changes according to the error you got
name: wgs
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - mamba
  - sra-tools
  - fastp=0.23.2
  - fastqc=0.12.1
  - multiqc=1.15
  - spades           # no version, let conda pick compatible
  - unicycler=0.5.0
  - quast=5.2.0
  - prokka=1.14.6
  - mlst=2.19.0
  - abricate=1.0.1
  - kraken2=2.1.2
  - bwa=0.7.17
  - samtools=1.17
  - bcftools=1.17
  - freebayes=1.3.5
  - mash=2.3
  - fastani=1.33
  - snippy=4.6.0
  - iqtree=2.2.2
  - python=3.11
  - pip
  - pip:
      - pyfastx

Perfect â€” your Docker image wgs_bacteria:1.0 has successfully built. ğŸ‰
To start using your WGS environment:

docker run -it --rm wgs_bacteria:1.0

To check it proper working 

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ docker run -it --rm wgs_bacteria:1.0
(base) root@0b1e1d613786:/work# conda env list
fastqc --version
spades.py --version
prokka --version

# conda environments:
#
# * -> active
# + -> frozen
base                 *   /opt/conda
wgs                      /opt/conda/envs/wgs

FastQC v0.12.1
/opt/conda/envs/wgs/share/spades/spades_pipeline/support.py:488: SyntaxWarning: invalid escape sequence '\d'
  return [atoi(c) for c in re.split("(\d+)", text)]
SPAdes genome ass

1ï¸âƒ£ Activate your WGS environment
conda activate wgs
spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ docker run -it --rm -v ~/wgs_bacteria_project:/work wgs_bacteria:1.0
(base) root@eec43db59d2d:/work# conda activate wgs
(wgs) root@eec43db59d2d:/work# 
Option 1: Update CA certificates inside container
apt-get update && apt-get install -y ca-certificates
update-ca-certificates
prefetch SRR36198494
fastq-dump --split-files --gzip SRR36198494


Troble shooting
conda remove -n wgs sra-tools
conda install -n wgs -c bioconda sra-tools

# Remove the old Bioconda sra-tools
conda remove -n wgs sra-tools

# Download and install NCBI SRA Toolkit (OpenSSL version)
wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz
tar -xvzf sratoolkit.current-ubuntu64.tar.gz
export PATH=$PWD/sratoolkit.current-ubuntu64/bin:$PATH

# Test
prefetch --version
fastq-dump --version
# Add SRA Toolkit to PATH
export PATH=$PWD/sratoolkit.3.2.1-ubuntu64/bin:$PATH

# Verify
prefetch --version
fasterq-dump --version
# Download SRR to /work (mounted to host)
prefetch SRR36198494

# Convert to gzipped FASTQ
fasterq-dump SRR36198494 --split-files --gzip

âœ… Step 1 â€” Find where your FASTQ files are on your host machine

You created the container earlier like this:

docker run -it \
  -v /home/spiseq/wgs_bacteria_project:/work \
  wgs_bacteria:1.0

Perfect â€” your data is in the correct folder:

/home/spiseq/wgs_bacteria_project/
    â”œâ”€â”€ SRR36198494_1.fastq.gz
    â”œâ”€â”€ SRR36198494_2.fastq.gz
    â””â”€â”€ SRR36198494/SRR36198494.sra


Now you can continue the analysis exactly from where you stopped.

âœ… Step 1 â€” Start the container with the correct mount

Run this on your host:

docker run -it \
  -v /home/spiseq/wgs_bacteria_project:/work \
  wgs_bacteria:1.0


You will enter:

(base) root@xxxx:/work#

âœ… Step 2 â€” Move into the working directory

Inside container:

cd /work
ls -lh


You should now see:

SRR36198494_1.fastq.gz
SRR36198494_2.fastq.gz
SRR36198494/

âœ… Step 3 â€” Activate the WGS environment
conda activate wgs


Prompt will change:

(wgs) root@xxxx:/work#

ğŸ¯ Now you can continue from the next pipeline step

You already completed:

prefetch

fasterq-dump

gzip

So next steps are:


So your FASTQ files should be in the directory where you ran the command yesterday.

âœ… Step 1 â€” Create the FastQC output directory

Inside the container (you are already inside):

mkdir -p fastqc_output

âœ… Step 2 â€” Run FastQC again
fastqc SRR36198494_1.fastq.gz SRR36198494_2.fastq.gz -o fastqc_output


FastQC output will appear in:

/work/fastqc_output/SRR36198494_1_fastqc.html
/work/fastqc_output/SRR36198494_2_fastqc.html

âœ… 1. SRA â€œrawâ€ data is not always raw

Most SRA submissions are pre-processed by the authors before upload.

Typical steps done before depositing to SRA:

âœ” Adapter removal
âœ” Quality trimming
âœ” Removal of low-quality reads
âœ” Filtering short reads
âœ” Removal of PhiX

This is especially common for:

Bacterial WGS

Metagenomics

Large datasets (NovaSeq / HiSeq)

High coverage (100â€“300X)

Because authors want to maximize assembly quality and ensure submissions pass NCBI QC.

SRA does not modify reads.
The cleaned files you see are exactly what the authors uploaded.

So adapters being completely absent is absolutely normal.

ğŸ› ï¸ 4. Tools used for trimming

The industry-standard tools:

â­ fastp (best, modern, super fast)
â­ Trimmomatic (older but widely used)
â­ cutadapt (very flexible, Python-based)

We will use fastp, since it is already installed in your Docker wgs environment.

Step 2: Run fastp for trimming

Even if your reads are clean, this teaches you how it's done.

ğŸš€ Example command:
fastp \
  -i SRR36198494_1.fastq.gz \
  -I SRR36198494_2.fastq.gz \
  -o trimmed_1.fastq.gz \
  -O trimmed_2.fastq.gz \
  --detect_adapter_for_pe \
  --qualified_quality_phred 20 \
  --length_required 50 \
  --thread 4 \
  --html fastp_report.html \
  --json fastp_report.json

What each parameter does:
Option	Meaning
-i, -I	Input R1 and R2
-o, -O	Output trimmed reads
--detect_adapter_for_pe	Automatically detects adapter sequence
--qualified_quality_phred 20	Trims low-quality bases (Q20)
--length_required 50	Removes reads < 50 bp
--thread 4	Speed
--html	Visual trimming report
--json	Full metadata

Output:

trimmed_1.fastq.gz
trimmed_2.fastq.gz
fastp_report.html
fastp_report.json

â–¶ï¸ Next Step in WGS Pipeline

Now that trimming is done, you should proceed to:

1ï¸âƒ£ Run FastQC again on the trimmed reads
fastqc trimmed_1.fastq.gz trimmed_2.fastq.gz -o fastqc_trimmed

2ï¸âƒ£ Run MultiQC

To summarize both raw + trimmed + fastp:

multiqc .

ğŸ”¬ SPAdes Command Explained (Line by Line)
spades.py \
  -1 trimmed_1.fastq.gz \
  -2 trimmed_2.fastq.gz \
  -o spades_output \
  --careful \
  -t 4 \
  -m 16

1. Input Files (-1 and -2)

-1 trimmed_1.fastq.gz â†’ forward reads (paired-end)

-2 trimmed_2.fastq.gz â†’ reverse reads (paired-end)

Inside SPAdes:

It reads the paired-end sequences and loads them into memory.

Performs error correction (unless --only-assembler is used) to correct sequencing mistakes, which is crucial for high-quality assembly.


Step 3: Assess assembly quality

Use QUAST to evaluate contigs/scaffolds:

quast.py spades_output/contigs.fasta -o quast_results/ -t 4


Key metrics:

N50 â†’ contig length where 50% of assembly is in contigs of this size or longer.

Total length â†’ should roughly match expected genome size (~5 Mb for E. coli).

# contigs â†’ ideally <100 for a bacterial genome.

GC content â†’ check against known species.

Optional: visualize assembly graph using Bandage:

Bandage GUI spades_output/assembly_graph.fastg


Allows you to see complex repeats or unresolved regions.


3. Next steps

Quality assessment

Use QUAST to check contig/scaffold N50, genome size, GC content:

quast.py spades_output/contigs.fasta -o quast_results/ -t 4
quast.py spades_output/scaffolds.fasta -o quast_results_scaffolds/ -t 4

1. Optional: Polishing the assembly (improve accuracy)

Even with a good draft, polishing corrects small indels, SNPs, and misassemblies using your original reads. A common tool: Pilon.

Steps:

# 1. Index scaffolds
bwa index spades_output/scaffolds.fasta

# 2. Map trimmed reads
bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads.bam
samtools index reads.bam

# 3. Run Pilon polishing
pilon --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


Output: polished_scaffolds.fasta

This reduces residual sequencing errors.

Step 1: Index the scaffolds
bwa index spades_output/scaffolds.fasta


What it does:

bwa index prepares your assembled scaffolds (FASTA file) for fast read alignment.

It creates multiple index files (suffix array, BWT, etc.) that allow BWA to quickly map millions of reads to the assembly.

Why it's needed:

Alignment tools like BWA cannot map reads to a genome without an index.

Think of it as creating a "searchable dictionary" of your genome.

Step 2: Map reads to the assembly
bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads.bam
samtools index reads.bam


Breaking it down:

bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz

Maps your paired-end trimmed reads (trimmed_1 and trimmed_2) back to the assembly (scaffolds.fasta).

-t 4 tells BWA to use 4 CPU threads (faster alignment).

Output is a SAM format stream (text-based alignment info).

| samtools sort -o reads.bam

Pipes the SAM output into samtools, which:

Converts it into BAM (binary format, smaller and faster).

Sorts reads by genomic position, which Pilon requires.

samtools index reads.bam

Creates an index file (reads.bam.bai) so Pilon can quickly access reads at any genome position.

Purpose:

Pilon uses these alignments to see where reads disagree with the assembly, identifying errors to correct.

Step 3: Run Pilon polishing
pilon --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


Breaking it down:

--genome spades_output/scaffolds.fasta

The assembly FASTA to be polished (input).

--frags reads.bam

The aligned reads (BAM file) that Pilon uses as evidence for corrections.

â€œFragsâ€ means paired-end or single reads mapped to the assembly.

--output polished_scaffolds

The prefix for output files.

Pilon generates:

polished_scaffolds.fasta â†’ corrected genome

polished_scaffolds.vcf â†’ all variants Pilon corrected

polished_scaffolds.changes â†’ summary of fixes

--threads 4

Use 4 CPU threads for faster processing.

What Pilon does internally:

Looks at each position in the assembly and the pileup of aligned reads.

Corrects:

Single nucleotide mismatches

Small insertions/deletions

Small misassemblies or gaps

Generates an error-corrected assembly ready for annotation.

Summary
Step	Purpose
bwa index	Prepare assembly for read mapping.
bwa mem + samtools	Map reads back to assembly; sort & index BAM for Pilon.
pilon	Compare reads to assembly; correct errors; produce polished genome.

âœ… After this workflow, your polished_scaffolds.fasta will be more accurate at the base level, reducing sequencing errors and improving gene predictions.

Option 1: Install Pilon locally

Download the latest Pilon jar:

wget https://github.com/broadinstitute/pilon/releases/download/v1.24/pilon-1.24.jar


This downloads the jar file to your current directory.

Run Pilon using Java:

java -Xmx16G -jar pilon-1.24.jar --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


-Xmx16G â†’ allocates 16 GB RAM (adjust to your system).

All other arguments are the same as before.

Pilon is a Java program, so you run it via java -jar pilon.jar rather than just pilon.

1. Run QUAST again on the polished genome

This checks if N50, number of contigs, or assembly size improved.

quast.py polished_scaffolds.fasta -o quast_polished -t 4

2. (Optional but recommended) Run a second round of Pilon

Many pipelines run 2â€“3 polishing rounds, because the first round fixes errors that improve read mapping for the next round.

Round 2:
bwa mem -t 4 polished_scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads2.bam
samtools index reads2.bam

java -Xmx16G -jar pilon-1.24.jar \
  --genome polished_scaffolds.fasta \
  --frags reads2.bam \
  --output polished_round2 \
  --threads 4

âœ… NEXT STEP: Genome Annotation (Bakta or Prokka)

Annotation identifies:

genes

rRNAs, tRNAs

CDS functions

AMR genes

virulence genes

plasmid markers

secretion systems

operons

Option A â€” Bakta (modern, best for bacterial WGS)

If you want the most accurate and curated annotation (recommended):

1. Install Bakta
conda install -c conda-forge -c bioconda bakta

mkdir -p bakta_db
bakta_db download --type light --output bakta_db

Baktaâ€™s light database (~1.5 GB) is small , it contains curated, high-quality biological datasets used for accurate genome annotation.
ğŸ“Œ Your pipeline so far

âœ” QC
âœ” Trimming
âœ” SPAdes assembly
âœ” Polishing (Pilon)
âœ” QUAST quality check
â¬… Next: Annotation (Bakta)
Then optionally AMR, MLST, plasmids, virulence.

âœ… Step 2 â€” Run Bakta with the correct DB path

Use the actual path inside your container:

bakta --db /work/bakta_db/db-light --threads 4 --output bakta_output polished_scaffolds.fasta

5. How to quantify completeness exactly

conda install -c bioconda -c conda-forge busco
busco --version
BUSCO requires a lineage dataset (you need bacteria_odb10).

Download it:

busco --download bacteria_odb10

ğŸ” 3. Run BUSCO after installation

Once BUSCO is installed and the DB is downloaded:

busco -i polished_scaffolds.fasta -l bacteria_odb10 -o busco_out -m genome --cpu 4

â­ Final Interpretation (concise)
Metric	Meaning
C = 100%	Genome is fully represented
S = 4.8%	Very low contiguity
D = 95.2%	High redundancy â†’ fragmented assembly
F = 0%	No broken genes
M = 0%	No missing genes

2ï¸âƒ£ AMR, virulence, plasmid analysis (very important)

Install tools if needed:

conda install -c bioconda abricate
abricate --setupdb


Run on polished genome:

abricate polished_scaffolds.fasta > abricate_results.tsv

Nice â€” letâ€™s move forward. Since youâ€™ve got a polished, annotated assembly and confirmed no AMR hits, the most useful next steps (practical, fast, and informative) are:

1) identify the strain/species and sequence type (ANI / GTDB-Tk / MLST) â€” tells you what organism you have;
2) detect plasmids & replicons (MOB-suite / PlasmidFinder) â€” find mobile elements that could carry AMR or virulence;
3) screen for virulence factors and prophages â€” biological context;
4) produce final QC (CheckM / BUSCO already done) and prepare NCBI submission if you want to share the genome.

1) Species identification & typing (fastANI + mlst)

FastANI gives pairwise ANI vs a reference; mlst gives sequence type for many species.
# install if missing
conda install -y -c bioconda fastani mlst
# install if missing
conda install -y -c bioconda fastani mlst

# Option A: fastANI vs a reference file (if you have a candidate ref)
fastani -q polished_scaffolds.fasta -r /path/to/closest_reference.fna -o fastani_out.txt --fragLen 1000

# Option B: search a collection of refs (if you have a folder 'refs/')
# fastani will produce a table of best matches
fastani -q polished_scaffolds.fasta -r refs/*.fna -o fastani_multi_out.txt

# MLST (auto-detects scheme)
mlst polished_scaffolds.fasta > mlst_result.txt

if above does nt work
ğŸ§° Steps to download reference genomes for your species

Here's a minimal workflow using commandâ€‘line tools:
âœ… How to fix / workaround

Option 1: Use wget instead (simpler and works over HTTP/HTTPS)

wget https://ftp.ncbi.nlm.nih.gov/genomes/ASSEMBLY_REPORTS/assembly_summary_refseq.txt


This downloads the same file via standard HTTP.

Less likely to be blocked by firewalls.

File size: ~20â€“25â€¯MB â†’ should finish in seconds.

Check it after download:

ls -lh assembly_summary_refseq.txt
head assembly_summary_refseq.txt
Next steps: filter for L.â€¯plantarum

Search for the old species name:

grep -E 'Lactobacillus plantarum' assembly_summary_refseq.txt > plantarum_list.txt


Check how many lines matched:

wc -l plantarum_list.txt
head plantarum_list.txt


You should see entries with the FTP paths to the genome assemblies.

Create a folder for your reference genomes:

mkdir -p ref_genomes


Download one or more high-quality assemblies (preferably â€œreferenceâ€ or â€œrepresentativeâ€):

Extract the FTP paths from plantarum_list.txt. The FTP path is in column 20. For example:

awk -F '\t' '{print $20}' plantarum_list.txt

Download one or more high-quality assemblies (preferably â€œreferenceâ€ or â€œrepresentativeâ€):

Extract the FTP paths from plantarum_list.txt. The FTP path is in column 20. For example:

awk -F '\t' '{print $20}' plantarum_list.txt

âœ… Download the reference genome FASTA(s)

Suppose you have an FTP path like:

https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/474/695/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly


Do this:

# Make a directory for reference genomes
mkdir -p ref_genomes
cd ref_genomes

# Download the genomic FASTA (compressed) â€” add â€œ_genomic.fna.gzâ€
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/474/695/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna.gz

# Repeat for other URLs (change the path accordingly)


Then decompress:

gunzip *.fna.gz



1. Run fastANI

Assuming your polished genome is polished_scaffolds.fasta and your references are in ref_genomes/:

fastANI -q /work/polished_scaffolds.fasta -r *.fna -o /work/ani_results.txt

Your output
/work/polished_scaffolds.fasta  GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna  98.3665  925  1580
/work/polished_scaffolds.fasta  GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna  98.3665  925  1580


Columns:

Query genome â†’ your polished genome

Reference genome â†’ the WJL strain of Lactobacillus plantarum

ANI (%) â†’ 98.37

Fragments matched â†’ 925

Total query fragments â†’ 1580

1. Install or check snippy

snippy is a fast and widely used tool for bacterial SNP calling. You should have it in your environment. If not:

conda install -c bioconda snippy

2. Run snippy
snippy --cpus 4 \
       --outdir snippy_out \
       --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
       --ctgs /work/polished_scaffolds.fasta


--ref â†’ the reference genome (WJL strain)

--ctgs â†’ your polished assembly

--outdir â†’ output directory

--cpus â†’ number of threads to speed up

3. Generate a core alignment for phylogeny

snippy-core --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
            --prefix core_alignment snippy_out

Produces core.full.aln â€” multiple alignment of core SNPs across genomes (here just one query vs reference, but can add more later)

Perfect â€” to generate a meaningful phylogenetic tree, you need at least 3 genomes. You already have your polished genome and the WJL reference; now weâ€™ll add 2â€“3 more L.â€¯plantarum reference genomes from NCBI RefSeq. Once you have them, weâ€™ll run snippy for each and build a tree with IQ-TREE.

Hereâ€™s a step-by-step plan:

1ï¸âƒ£ Download additional reference genomes

Example additional references (FASTA files):

# Make sure you are in the ref_genomes folder
cd /work/ref_genomes

# Download a few more L. plantarum genomes
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/507/045/GCF_000507045.1_Velvet_for_Version_1.2.03_of_the_Lactobacillus_plantarum_genome/GCF_000507045.1_Velvet_for_Version_1.2.03_of_the_Lactobacillus_plantarum_genome_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/001/302/645/GCF_001302645.1_ASM130264v1/GCF_001302645.1_ASM130264v1_genomic.fna.gz
wget ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/965/213/325/GCF_965213325.1_isolate_VK_MK/GCF_965213325.1_isolate_VK_MK_genomic.fna.gz

# Decompress
gunzip *.fna.gz

2ï¸âƒ£ Run Snippy for each genome

Youâ€™ll map your polished genome against each reference separately:

# WJL reference (already done)
snippy --cpus 4 --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna --ctgs /work/polished_scaffolds.fasta --outdir snippy_WJL

# New references
snippy --cpus 4 --ref /work/ref_genomes/GCF_000507045.1_*.fna --ctgs /work/polished_scaffolds.fasta --outdir snippy_507045
snippy --cpus 4 --ref /work/ref_genomes/GCF_001302645.1_*.fna --ctgs /work/polished_scaffolds.fasta --outdir snippy_130264
snippy --cpus 4 --ref /work/ref_genomes/GCF_965213325.1_*.fna --ctgs /work/polished_scaffolds.fasta --outdir snippy_965213325


Each snippy_* folder will contain the SNPs and aligned sequences.

3ï¸âƒ£ Generate core alignment

Now run snippy-core including all Snippy output folders:

snippy-core --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
            --prefix core_multi snippy_WJL snippy_507045 snippy_130264 snippy_965213325


Produces core_multi.full.aln â€” alignment of all genomes

Produces core_multi.core.aln â€” core SNP alignment

4ï¸âƒ£ Build the phylogenetic tree
iqtree -s core_multi.full.aln -m GTR+G -bb 1000 -nt AUTO


Produces the ML tree with bootstrap support

Output: core_multi.full.aln.treefile

Solutions

Map all query genomes to the same reference genome

For example, choose GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna as the reference:

# Run all Snippy runs again, but use the WJL reference
snippy --cpus 4 \
       --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
       --ctgs /work/polished_scaffolds.fasta \
       --outdir snippy_WJL \
       --force

snippy --cpus 4 \
       --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
       --ctgs /work/ref_genomes/GCF_000507045.1_Velvet_for_Version_1.2.03_of_the_Lactobacillus_plantarum_genome_genomic.fna \
       --outdir snippy_507045_WJL \
       --force

snippy --cpus 4 \
       --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
       --ctgs /work/ref_genomes/GCF_001302645.1_ASM130264v1_genomic.fna \
       --outdir snippy_130264_WJL \
       --force


Then run Snippy-core:

snippy-core --ref /work/ref_genomes/GCF_000474695.1_Lactobacillus_plantarum_WJL_genome_Assembly_genomic.fna \
            --prefix core_multi \
            /work/ref_genomes/snippy_WJL \
            /work/ref_genomes/snippy_507045_WJL \
            /work/ref_genomes/snippy_130264_WJL


âœ… Key point: All sequences must be aligned to the same reference genome before you can generate a core alignment.

If you want, I can write a ready-to-run workflow for all your L.â€¯plantarum genomes that will produce a core alignment and IQ-TREE phylogeny in one go. This avoids all reference mismatch errors. Do you want me to do that?

2ï¸âƒ£ Inspect the alignment (optional)
# Check the first few lines
head core_multi.full.aln

# Summary statistics
grep -c ">" core_multi.full.aln  # number of sequences

3ï¸âƒ£ Build a phylogenetic tree with IQ-TREE
iqtree -s core_multi.full.aln \
       -m GTR+G \
       -bb 1000 \
       -nt AUTO


-bb 1000 â†’ 1000 ultrafast bootstrap replicates.

-nt AUTO â†’ uses all available CPU threads.

Output: core_multi.full.aln.treefile, .log, .iqtree, .ckp.gz.

4ï¸âƒ£ Optional: visualize the tree
# Example using FigTree or iTOL
# FigTree: open core_multi.full.aln.treefile
# iTOL: upload the .treefile


âœ… After this, youâ€™ll have a core genome SNP phylogeny for all your L.â€¯plantarum strains.

If you want, I can also show a quick way to add metadata and annotate the tree, so you can see which isolate is which visually. Do you want me to do that next?

1ï¸âƒ£ Add metadata & annotate the tree (visualization)

Create a simple metadata table (CSV or TSV) with columns like:

strain   source   collection_date   location


Use iTOL (Interactive Tree Of Life) or FigTree to upload the .treefile from IQ-TREE and annotate branches with metadata.

Color-code strains, highlight clusters, or mark AMR/virulence profiles.

2ï¸âƒ£ Optional: Detect plasmids and mobile elements

Install MOB-suite (if not already):

conda install -c bioconda mob_suite


Run on polished assembly:

mob_recon -i polished_scaffolds.fasta -o mob_results


This gives plasmid types, replicons, and AMR genes carried on plasmids.

3ï¸âƒ£ Screen for virulence factors & prophages

Virulence genes: Use ABRicate with VFDB database:

abricate --db vfdb polished_scaffolds.fasta > vfdb_results.tsv


Prophages: Install PHASTER locally or submit sequences to PHASTER web server.

4ï¸âƒ£ Final QC / completeness check

If not already done:

busco -i polished_scaffolds.fasta -l bacteria_odb10 -o busco_final -m genome --cpu 4


Confirm genome completeness and check for any fragmented or missing genes.

5ï¸âƒ£ Optional: Prepare for NCBI submission

Use Bakta/Prokka annotation output for GenBank/FASTA files.

Automate the workflow: Create a shell script or Snakemake workflow to rerun the pipeline easily for multiple isolates.

Organize your results clearly:

wgs_bacteria_project/
â”œâ”€â”€ raw_data/
â”œâ”€â”€ fastqc_output/
â”œâ”€â”€ trimmed_reads/
â”œâ”€â”€ spades_output/
â”œâ”€â”€ quast_results/
â”œâ”€â”€ polished_scaffolds.fasta
â”œâ”€â”€ bakta_output/
â”œâ”€â”€ abricate_results.tsv
â”œâ”€â”€ ref_genomes/
â”œâ”€â”€ snippy_core/
â”œâ”€â”€ phylogeny/
â””â”€â”€ metadata/


This structure keeps everything reproducible and shareable.
