Get docker installed in ubuntu, refer docker readme

Then

Step 3 â€” Create & build the unified WGS Docker image (detailed)
Goal: produce a reproducible Docker image wgs_bacteria:1.0 that contains all tools for the WGS pipeline (download, QC, trim, assembly, typing, AMR, phylogeny).

Work from your project root â€” the same $PROJECT you created earlier (e.g. ~/wgs_bacteria_project).

3.1 â€” Create the files

Open a terminal and run these commands (they create files with the exact contents we discussed):

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/Desktop$ cd ~/wgs_bacteria_project
pwd
ls
/home/spiseq/wgs_bacteria_project
spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ 

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ # create Dockerfile
cat > Dockerfile <<'EOF'
# Dockerfile â€” unified bacterial WGS image
FROM continuumio/miniconda3:latest

ENV DEBIAN_FRONTEND=noninteractive
SHELL ["/bin/bash", "-o", "pipefail", "-c"]

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      build-essential ca-certificates curl wget git unzip bzip2 \
      libbz2-dev liblzma-dev libzstd1 pigz procps && \
    apt-get clean && rm -rf /var/lib/apt/lists/*

COPY environment.yml /tmp/environment.yml

RUN conda install -y -n base -c conda-forge mamba && \
    mamba env create -n wgs -f /tmp/environment.yml && \
    conda clean -afy && \
    rm -f /tmp/environment.yml

SHELL ["conda", "run", "-n", "wgs", "/bin/bash", "-lc"]
ENV PATH=/opt/conda/envs/wgs/bin:$PATH
WORKDIR /work
ENTRYPOINT [ "/bin/bash" ]
EOF

Step 3.2 â€” Build the Docker image

Run this command from inside ~/wgs_bacteria_project:

docker build -t wgs_bacteria:1.0 .

What this does:

Starts from continuumio/miniconda3:latest.

Installs system packages (apt-get).

Copies environment.yml into the image.

Installs mamba and uses it to create the wgs Conda environment.

Cleans temporary files to reduce image size.

Sets the working directory to /work and exposes the wgs environment binaries on PATH.

What we are doing step by step

Create a list of all required packages and versions

Thatâ€™s what the environment.yml file is.

It lists every bioinformatics tool you need for bacterial WGS (FastQC, fastp, SPAdes, Prokka, etc.) with specific versions.

Pinning versions ensures reproducibility: if you rebuild later, the same versions are installed.

Create a Dockerfile

The Dockerfile is a â€œrecipeâ€ for a container.

It starts from a clean base image (Miniconda) and tells Docker how to build the container.

Steps include installing system packages, copying environment.yml, installing mamba, and creating a conda environment inside the image.

Build the Docker image

When you run docker build -t wgs_bacteria:1.0 ., Docker executes the Dockerfile instructions step by step:

Install OS dependencies

Copy environment.yml

Install mamba and create the wgs environment with all tools inside the image

Clean up to reduce image size

At the end, you get a self-contained Docker image that has all WGS tools installed and ready to use.

Use the Docker image

You can now run the container with docker run and all tools will be available inside it.

Your host OS is unaffected â€” nothing is installed globally.

You can mount your project folder so data and results are accessible outside the container.

1ï¸âƒ£ Docker image storage

When you run:

docker build -t wgs_bacteria:1.0 .


Docker creates an image, which is like a snapshot of a Linux system with all your tools installed.

This image lives inside Dockerâ€™s storage on your host, not in your project folder.

Location depends on your OS:

OS	Default Docker storage path
Linux	/var/lib/docker
macOS	inside Docker Desktop VM
Windows	inside Docker Desktop VM

You cannot directly see the files in ~/wgs_bacteria_project; Docker manages them internally.

The image contains all system packages, conda, and tools â€” fully isolated.

Key points:

Dockerfile: Already created, contains all steps to install system packages, copy environment.yml, install mamba, create wgs environment, and set /work as working directory.

Environment: mamba will read your environment.yml and install all WGS tools.

Output: At the end, you will have an image called wgs_bacteria:1.0.

If you face any error in installation of package for docker

1ï¸âƒ£ Save the environment.yml

Inside your project folder (~/wgs_bacteria_project):

nano environment.yml

Then make changes according to the error you got
name: wgs
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies:
  - mamba
  - sra-tools
  - fastp=0.23.2
  - fastqc=0.12.1
  - multiqc=1.15
  - spades           # no version, let conda pick compatible
  - unicycler=0.5.0
  - quast=5.2.0
  - prokka=1.14.6
  - mlst=2.19.0
  - abricate=1.0.1
  - kraken2=2.1.2
  - bwa=0.7.17
  - samtools=1.17
  - bcftools=1.17
  - freebayes=1.3.5
  - mash=2.3
  - fastani=1.33
  - snippy=4.6.0
  - iqtree=2.2.2
  - python=3.11
  - pip
  - pip:
      - pyfastx

Perfect â€” your Docker image wgs_bacteria:1.0 has successfully built. ğŸ‰
To start using your WGS environment:

docker run -it --rm wgs_bacteria:1.0

To check it proper working 

spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ docker run -it --rm wgs_bacteria:1.0
(base) root@0b1e1d613786:/work# conda env list
fastqc --version
spades.py --version
prokka --version

# conda environments:
#
# * -> active
# + -> frozen
base                 *   /opt/conda
wgs                      /opt/conda/envs/wgs

FastQC v0.12.1
/opt/conda/envs/wgs/share/spades/spades_pipeline/support.py:488: SyntaxWarning: invalid escape sequence '\d'
  return [atoi(c) for c in re.split("(\d+)", text)]
SPAdes genome ass

1ï¸âƒ£ Activate your WGS environment
conda activate wgs
spiseq@ASUS-TUF-Gaming-F15-FX506HF-FX506HF:~/wgs_bacteria_project$ docker run -it --rm -v ~/wgs_bacteria_project:/work wgs_bacteria:1.0
(base) root@eec43db59d2d:/work# conda activate wgs
(wgs) root@eec43db59d2d:/work# 
Option 1: Update CA certificates inside container
apt-get update && apt-get install -y ca-certificates
update-ca-certificates
prefetch SRR36198494
fastq-dump --split-files --gzip SRR36198494


Troble shooting
conda remove -n wgs sra-tools
conda install -n wgs -c bioconda sra-tools

# Remove the old Bioconda sra-tools
conda remove -n wgs sra-tools

# Download and install NCBI SRA Toolkit (OpenSSL version)
wget https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-ubuntu64.tar.gz
tar -xvzf sratoolkit.current-ubuntu64.tar.gz
export PATH=$PWD/sratoolkit.current-ubuntu64/bin:$PATH

# Test
prefetch --version
fastq-dump --version
# Add SRA Toolkit to PATH
export PATH=$PWD/sratoolkit.3.2.1-ubuntu64/bin:$PATH

# Verify
prefetch --version
fasterq-dump --version
# Download SRR to /work (mounted to host)
prefetch SRR36198494

# Convert to gzipped FASTQ
fasterq-dump SRR36198494 --split-files --gzip

âœ… Step 1 â€” Find where your FASTQ files are on your host machine

You created the container earlier like this:

docker run -it \
  -v /home/spiseq/wgs_bacteria_project:/work \
  wgs_bacteria:1.0

Perfect â€” your data is in the correct folder:

/home/spiseq/wgs_bacteria_project/
    â”œâ”€â”€ SRR36198494_1.fastq.gz
    â”œâ”€â”€ SRR36198494_2.fastq.gz
    â””â”€â”€ SRR36198494/SRR36198494.sra


Now you can continue the analysis exactly from where you stopped.

âœ… Step 1 â€” Start the container with the correct mount

Run this on your host:

docker run -it \
  -v /home/spiseq/wgs_bacteria_project:/work \
  wgs_bacteria:1.0


You will enter:

(base) root@xxxx:/work#

âœ… Step 2 â€” Move into the working directory

Inside container:

cd /work
ls -lh


You should now see:

SRR36198494_1.fastq.gz
SRR36198494_2.fastq.gz
SRR36198494/

âœ… Step 3 â€” Activate the WGS environment
conda activate wgs


Prompt will change:

(wgs) root@xxxx:/work#

ğŸ¯ Now you can continue from the next pipeline step

You already completed:

prefetch

fasterq-dump

gzip

So next steps are:


So your FASTQ files should be in the directory where you ran the command yesterday.

âœ… Step 1 â€” Create the FastQC output directory

Inside the container (you are already inside):

mkdir -p fastqc_output

âœ… Step 2 â€” Run FastQC again
fastqc SRR36198494_1.fastq.gz SRR36198494_2.fastq.gz -o fastqc_output


FastQC output will appear in:

/work/fastqc_output/SRR36198494_1_fastqc.html
/work/fastqc_output/SRR36198494_2_fastqc.html

âœ… 1. SRA â€œrawâ€ data is not always raw

Most SRA submissions are pre-processed by the authors before upload.

Typical steps done before depositing to SRA:

âœ” Adapter removal
âœ” Quality trimming
âœ” Removal of low-quality reads
âœ” Filtering short reads
âœ” Removal of PhiX

This is especially common for:

Bacterial WGS

Metagenomics

Large datasets (NovaSeq / HiSeq)

High coverage (100â€“300X)

Because authors want to maximize assembly quality and ensure submissions pass NCBI QC.

SRA does not modify reads.
The cleaned files you see are exactly what the authors uploaded.

So adapters being completely absent is absolutely normal.

ğŸ› ï¸ 4. Tools used for trimming

The industry-standard tools:

â­ fastp (best, modern, super fast)
â­ Trimmomatic (older but widely used)
â­ cutadapt (very flexible, Python-based)

We will use fastp, since it is already installed in your Docker wgs environment.

Step 2: Run fastp for trimming

Even if your reads are clean, this teaches you how it's done.

ğŸš€ Example command:
fastp \
  -i SRR36198494_1.fastq.gz \
  -I SRR36198494_2.fastq.gz \
  -o trimmed_1.fastq.gz \
  -O trimmed_2.fastq.gz \
  --detect_adapter_for_pe \
  --qualified_quality_phred 20 \
  --length_required 50 \
  --thread 4 \
  --html fastp_report.html \
  --json fastp_report.json

What each parameter does:
Option	Meaning
-i, -I	Input R1 and R2
-o, -O	Output trimmed reads
--detect_adapter_for_pe	Automatically detects adapter sequence
--qualified_quality_phred 20	Trims low-quality bases (Q20)
--length_required 50	Removes reads < 50 bp
--thread 4	Speed
--html	Visual trimming report
--json	Full metadata

Output:

trimmed_1.fastq.gz
trimmed_2.fastq.gz
fastp_report.html
fastp_report.json

â–¶ï¸ Next Step in WGS Pipeline

Now that trimming is done, you should proceed to:

1ï¸âƒ£ Run FastQC again on the trimmed reads
fastqc trimmed_1.fastq.gz trimmed_2.fastq.gz -o fastqc_trimmed

2ï¸âƒ£ Run MultiQC

To summarize both raw + trimmed + fastp:

multiqc .

ğŸ”¬ SPAdes Command Explained (Line by Line)
spades.py \
  -1 trimmed_1.fastq.gz \
  -2 trimmed_2.fastq.gz \
  -o spades_output \
  --careful \
  -t 4 \
  -m 16

1. Input Files (-1 and -2)

-1 trimmed_1.fastq.gz â†’ forward reads (paired-end)

-2 trimmed_2.fastq.gz â†’ reverse reads (paired-end)

Inside SPAdes:

It reads the paired-end sequences and loads them into memory.

Performs error correction (unless --only-assembler is used) to correct sequencing mistakes, which is crucial for high-quality assembly.


Step 3: Assess assembly quality

Use QUAST to evaluate contigs/scaffolds:

quast.py spades_output/contigs.fasta -o quast_results/ -t 4


Key metrics:

N50 â†’ contig length where 50% of assembly is in contigs of this size or longer.

Total length â†’ should roughly match expected genome size (~5 Mb for E. coli).

# contigs â†’ ideally <100 for a bacterial genome.

GC content â†’ check against known species.

Optional: visualize assembly graph using Bandage:

Bandage GUI spades_output/assembly_graph.fastg


Allows you to see complex repeats or unresolved regions.


3. Next steps

Quality assessment

Use QUAST to check contig/scaffold N50, genome size, GC content:

quast.py spades_output/contigs.fasta -o quast_results/ -t 4
quast.py spades_output/scaffolds.fasta -o quast_results_scaffolds/ -t 4

1. Optional: Polishing the assembly (improve accuracy)

Even with a good draft, polishing corrects small indels, SNPs, and misassemblies using your original reads. A common tool: Pilon.

Steps:

# 1. Index scaffolds
bwa index spades_output/scaffolds.fasta

# 2. Map trimmed reads
bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads.bam
samtools index reads.bam

# 3. Run Pilon polishing
pilon --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


Output: polished_scaffolds.fasta

This reduces residual sequencing errors.

Step 1: Index the scaffolds
bwa index spades_output/scaffolds.fasta


What it does:

bwa index prepares your assembled scaffolds (FASTA file) for fast read alignment.

It creates multiple index files (suffix array, BWT, etc.) that allow BWA to quickly map millions of reads to the assembly.

Why it's needed:

Alignment tools like BWA cannot map reads to a genome without an index.

Think of it as creating a "searchable dictionary" of your genome.

Step 2: Map reads to the assembly
bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads.bam
samtools index reads.bam


Breaking it down:

bwa mem -t 4 spades_output/scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz

Maps your paired-end trimmed reads (trimmed_1 and trimmed_2) back to the assembly (scaffolds.fasta).

-t 4 tells BWA to use 4 CPU threads (faster alignment).

Output is a SAM format stream (text-based alignment info).

| samtools sort -o reads.bam

Pipes the SAM output into samtools, which:

Converts it into BAM (binary format, smaller and faster).

Sorts reads by genomic position, which Pilon requires.

samtools index reads.bam

Creates an index file (reads.bam.bai) so Pilon can quickly access reads at any genome position.

Purpose:

Pilon uses these alignments to see where reads disagree with the assembly, identifying errors to correct.

Step 3: Run Pilon polishing
pilon --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


Breaking it down:

--genome spades_output/scaffolds.fasta

The assembly FASTA to be polished (input).

--frags reads.bam

The aligned reads (BAM file) that Pilon uses as evidence for corrections.

â€œFragsâ€ means paired-end or single reads mapped to the assembly.

--output polished_scaffolds

The prefix for output files.

Pilon generates:

polished_scaffolds.fasta â†’ corrected genome

polished_scaffolds.vcf â†’ all variants Pilon corrected

polished_scaffolds.changes â†’ summary of fixes

--threads 4

Use 4 CPU threads for faster processing.

What Pilon does internally:

Looks at each position in the assembly and the pileup of aligned reads.

Corrects:

Single nucleotide mismatches

Small insertions/deletions

Small misassemblies or gaps

Generates an error-corrected assembly ready for annotation.

Summary
Step	Purpose
bwa index	Prepare assembly for read mapping.
bwa mem + samtools	Map reads back to assembly; sort & index BAM for Pilon.
pilon	Compare reads to assembly; correct errors; produce polished genome.

âœ… After this workflow, your polished_scaffolds.fasta will be more accurate at the base level, reducing sequencing errors and improving gene predictions.

Option 1: Install Pilon locally

Download the latest Pilon jar:

wget https://github.com/broadinstitute/pilon/releases/download/v1.24/pilon-1.24.jar


This downloads the jar file to your current directory.

Run Pilon using Java:

java -Xmx16G -jar pilon-1.24.jar --genome spades_output/scaffolds.fasta --frags reads.bam --output polished_scaffolds --threads 4


-Xmx16G â†’ allocates 16 GB RAM (adjust to your system).

All other arguments are the same as before.

Pilon is a Java program, so you run it via java -jar pilon.jar rather than just pilon.

1. Run QUAST again on the polished genome

This checks if N50, number of contigs, or assembly size improved.

quast.py polished_scaffolds.fasta -o quast_polished -t 4

2. (Optional but recommended) Run a second round of Pilon

Many pipelines run 2â€“3 polishing rounds, because the first round fixes errors that improve read mapping for the next round.

Round 2:
bwa mem -t 4 polished_scaffolds.fasta trimmed_1.fastq.gz trimmed_2.fastq.gz | samtools sort -o reads2.bam
samtools index reads2.bam

java -Xmx16G -jar pilon-1.24.jar \
  --genome polished_scaffolds.fasta \
  --frags reads2.bam \
  --output polished_round2 \
  --threads 4

âœ… NEXT STEP: Genome Annotation (Bakta or Prokka)

Annotation identifies:

genes

rRNAs, tRNAs

CDS functions

AMR genes

virulence genes

plasmid markers

secretion systems

operons

Option A â€” Bakta (modern, best for bacterial WGS)

If you want the most accurate and curated annotation (recommended):

1. Install Bakta
conda install -c conda-forge -c bioconda bakta

mkdir -p bakta_db
bakta_db download --output bakta_db

Baktaâ€™s full database (~15â€“20 GB) is large because it contains curated, high-quality biological datasets used for accurate genome annotation.
ğŸ“Œ Your pipeline so far

âœ” QC
âœ” Trimming
âœ” SPAdes assembly
âœ” Polishing (Pilon)
âœ” QUAST quality check
â¬… Next: Annotation (Bakta)
Then optionally AMR, MLST, plasmids, virulence.
